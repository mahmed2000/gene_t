Training for TP53_8_8
Model 1
[Linear(in_features=3220, out_features=256, bias=True), Linear(in_features=256, out_features=64, bias=True), Linear(in_features=64, out_features=1, bias=True)]
cust_model(
  (model): Sequential(
    (0): Linear(in_features=3220, out_features=256, bias=True)
    (1): Linear(in_features=256, out_features=64, bias=True)
    (2): Linear(in_features=64, out_features=1, bias=True)
  )
  (activation): Sigmoid()
)
Epoch: 10	Acc: 0.816	Loss: 8.7287
Epoch: 20	Acc: 0.8636	Loss: 8.3039
Epoch: 30	Acc: 0.8798	Loss: 7.4257
Epoch: 40	Acc: 0.8911	Loss: 5.9151
Epoch: 50	Acc: 0.9061	Loss: 4.366
Epoch: 60	Acc: 0.9274	Loss: 3.3243
Epoch: 70	Acc: 0.9399	Loss: 2.7734
Epoch: 80	Acc: 0.9499	Loss: 2.4042
Epoch: 90	Acc: 0.9587	Loss: 2.1383
Epoch: 100	Acc: 0.9587	Loss: 2.1237
Epoch: 110	Acc: 0.9612	Loss: 1.8358
Epoch: 120	Acc: 0.965	Loss: 1.7095
Epoch: 130	Acc: 0.9612	Loss: 1.6749
Epoch: 140	Acc: 0.9675	Loss: 1.5992
Epoch: 150	Acc: 0.9687	Loss: 1.4758
Epoch: 160	Acc: 0.9662	Loss: 1.4367
Epoch: 170	Acc: 0.9687	Loss: 1.4815
Epoch: 180	Acc: 0.97	Loss: 1.3623
Epoch: 190	Acc: 0.97	Loss: 1.3469
Epoch: 200	Acc: 0.9737	Loss: 1.3257


              precision    recall  f1-score   support

           0       1.00      0.90      0.95        96
           1       0.91      1.00      0.95       104

    accuracy                           0.95       200
   macro avg       0.96      0.95      0.95       200
weighted avg       0.95      0.95      0.95       200

Model 2
[Linear(in_features=3220, out_features=256, bias=True), Dropout(p=0.25, inplace=False), Linear(in_features=256, out_features=64, bias=True), Dropout(p=0.25, inplace=False), Linear(in_features=64, out_features=1, bias=True)]
cust_model(
  (model): Sequential(
    (0): Linear(in_features=3220, out_features=256, bias=True)
    (1): Dropout(p=0.25, inplace=False)
    (2): Linear(in_features=256, out_features=64, bias=True)
    (3): Dropout(p=0.25, inplace=False)
    (4): Linear(in_features=64, out_features=1, bias=True)
  )
  (activation): Sigmoid()
)
Epoch: 10	Acc: 0.6521	Loss: 8.7605
Epoch: 20	Acc: 0.8235	Loss: 8.3454
Epoch: 30	Acc: 0.8436	Loss: 7.5207
Epoch: 40	Acc: 0.8936	Loss: 6.0799
Epoch: 50	Acc: 0.9124	Loss: 4.4418
Epoch: 60	Acc: 0.9287	Loss: 3.4123
Epoch: 70	Acc: 0.9387	Loss: 2.8483
Epoch: 80	Acc: 0.9524	Loss: 2.4496
Epoch: 90	Acc: 0.9524	Loss: 2.1917
Epoch: 100	Acc: 0.9587	Loss: 2.0187
Epoch: 110	Acc: 0.9612	Loss: 1.9033
Epoch: 120	Acc: 0.9599	Loss: 1.8452
Epoch: 130	Acc: 0.9612	Loss: 1.7014
Epoch: 140	Acc: 0.9625	Loss: 1.6959
Epoch: 150	Acc: 0.9662	Loss: 1.5875
Epoch: 160	Acc: 0.9675	Loss: 1.5742
Epoch: 170	Acc: 0.9637	Loss: 1.5077
Epoch: 180	Acc: 0.97	Loss: 1.398
Epoch: 190	Acc: 0.9687	Loss: 1.457
Epoch: 200	Acc: 0.9687	Loss: 1.4681


              precision    recall  f1-score   support

           0       1.00      0.91      0.95       102
           1       0.92      1.00      0.96        98

    accuracy                           0.95       200
   macro avg       0.96      0.96      0.95       200
weighted avg       0.96      0.95      0.95       200

Model 3
[Linear(in_features=64, out_features=256, bias=True), Linear(in_features=256, out_features=64, bias=True), Linear(in_features=64, out_features=1, bias=True)]
cust_model(
  (conv): Conv1d(1, 64, kernel_size=(8,), stride=(1,))
  (maxpool): MaxPool1d(kernel_size=3213, stride=3213, padding=0, dilation=1, ceil_mode=False)
  (model): Sequential(
    (0): Linear(in_features=64, out_features=256, bias=True)
    (1): Linear(in_features=256, out_features=64, bias=True)
    (2): Linear(in_features=64, out_features=1, bias=True)
  )
  (activation): Sigmoid()
)
Epoch: 10	Acc: 0.5081	Loss: 8.9987
Epoch: 20	Acc: 0.5106	Loss: 8.9853
Epoch: 30	Acc: 0.5144	Loss: 8.9752
Epoch: 40	Acc: 0.5094	Loss: 8.9592
Epoch: 50	Acc: 0.5369	Loss: 8.9501
Epoch: 60	Acc: 0.5169	Loss: 8.9281
Epoch: 70	Acc: 0.7334	Loss: 8.8994
Epoch: 80	Acc: 0.6971	Loss: 8.8717
Epoch: 90	Acc: 0.7647	Loss: 8.8387
Epoch: 100	Acc: 0.7497	Loss: 8.7962


              precision    recall  f1-score   support

           0       0.97      0.63      0.77       101
           1       0.72      0.98      0.83        99

    accuracy                           0.81       200
   macro avg       0.85      0.81      0.80       200
weighted avg       0.85      0.81      0.80       200

