Training for TP53_8_8
Model 1
[Linear(in_features=3220, out_features=256, bias=True), Linear(in_features=256, out_features=64, bias=True), Linear(in_features=64, out_features=1, bias=True)]
cust_model(
  (model): Sequential(
    (0): Linear(in_features=3220, out_features=256, bias=True)
    (1): Linear(in_features=256, out_features=64, bias=True)
    (2): Linear(in_features=64, out_features=1, bias=True)
  )
  (activation): Sigmoid()
)
Epoch: 10	Acc: 0.821	Loss: 8.7774
Epoch: 20	Acc: 0.9086	Loss: 8.3837
Epoch: 30	Acc: 0.8723	Loss: 7.5827
Epoch: 40	Acc: 0.8961	Loss: 6.1179
Epoch: 50	Acc: 0.9186	Loss: 4.4765
Epoch: 60	Acc: 0.9299	Loss: 3.4145
Epoch: 70	Acc: 0.9387	Loss: 2.7565
Epoch: 80	Acc: 0.9524	Loss: 2.4397
Epoch: 90	Acc: 0.9524	Loss: 2.1504
Epoch: 100	Acc: 0.9612	Loss: 1.9055
Epoch: 110	Acc: 0.9587	Loss: 1.8139
Epoch: 120	Acc: 0.9612	Loss: 1.7168
Epoch: 130	Acc: 0.9625	Loss: 1.6688
Epoch: 140	Acc: 0.9637	Loss: 1.6175
Epoch: 150	Acc: 0.9637	Loss: 1.4717
Epoch: 160	Acc: 0.965	Loss: 1.4766
Epoch: 170	Acc: 0.9687	Loss: 1.4558
Epoch: 180	Acc: 0.9675	Loss: 1.3698
Epoch: 190	Acc: 0.9675	Loss: 1.3831
Epoch: 200	Acc: 0.97	Loss: 1.2815


              precision    recall  f1-score   support

           0       1.00      0.91      0.95        98
           1       0.92      1.00      0.96       102

    accuracy                           0.95       200
   macro avg       0.96      0.95      0.95       200
weighted avg       0.96      0.95      0.95       200

Model 2
[Linear(in_features=3220, out_features=256, bias=True), Dropout(p=0.25, inplace=False), Linear(in_features=256, out_features=64, bias=True), Dropout(p=0.25, inplace=False), Linear(in_features=64, out_features=1, bias=True)]
cust_model(
  (model): Sequential(
    (0): Linear(in_features=3220, out_features=256, bias=True)
    (1): Dropout(p=0.25, inplace=False)
    (2): Linear(in_features=256, out_features=64, bias=True)
    (3): Dropout(p=0.25, inplace=False)
    (4): Linear(in_features=64, out_features=1, bias=True)
  )
  (activation): Sigmoid()
)
Epoch: 10	Acc: 0.8586	Loss: 8.6709
Epoch: 20	Acc: 0.8711	Loss: 8.0841
Epoch: 30	Acc: 0.8874	Loss: 6.9868
Epoch: 40	Acc: 0.8924	Loss: 5.2953
Epoch: 50	Acc: 0.9161	Loss: 3.8224
Epoch: 60	Acc: 0.9337	Loss: 3.085
Epoch: 70	Acc: 0.9387	Loss: 2.5022
Epoch: 80	Acc: 0.9499	Loss: 2.2695
Epoch: 90	Acc: 0.9574	Loss: 2.0556
Epoch: 100	Acc: 0.9587	Loss: 1.8799
Epoch: 110	Acc: 0.9612	Loss: 1.7104
Epoch: 120	Acc: 0.9612	Loss: 1.63
Epoch: 130	Acc: 0.9599	Loss: 1.568
Epoch: 140	Acc: 0.965	Loss: 1.529
Epoch: 150	Acc: 0.9662	Loss: 1.488
Epoch: 160	Acc: 0.9662	Loss: 1.3774
Epoch: 170	Acc: 0.9675	Loss: 1.4173
Epoch: 180	Acc: 0.9725	Loss: 1.2707
Epoch: 190	Acc: 0.97	Loss: 1.36
Epoch: 200	Acc: 0.97	Loss: 1.2332


              precision    recall  f1-score   support

           0       1.00      0.91      0.95        99
           1       0.92      1.00      0.96       101

    accuracy                           0.95       200
   macro avg       0.96      0.95      0.95       200
weighted avg       0.96      0.95      0.95       200

Model 3
[Linear(in_features=64, out_features=256, bias=True), Linear(in_features=256, out_features=64, bias=True), Linear(in_features=64, out_features=1, bias=True)]
cust_model(
  (conv): Conv1d(1, 64, kernel_size=(8,), stride=(1,))
  (maxpool): MaxPool1d(kernel_size=3213, stride=3213, padding=0, dilation=1, ceil_mode=False)
  (model): Sequential(
    (0): Linear(in_features=64, out_features=256, bias=True)
    (1): Linear(in_features=256, out_features=64, bias=True)
    (2): Linear(in_features=64, out_features=1, bias=True)
  )
  (activation): Sigmoid()
)
Epoch: 10	Acc: 0.4781	Loss: 9.0103
Epoch: 20	Acc: 0.5344	Loss: 8.9941
Epoch: 30	Acc: 0.5106	Loss: 8.9862
Epoch: 40	Acc: 0.5482	Loss: 8.9772
Epoch: 50	Acc: 0.6658	Loss: 8.9537
Epoch: 60	Acc: 0.6758	Loss: 8.932
Epoch: 70	Acc: 0.7334	Loss: 8.9085
Epoch: 80	Acc: 0.7447	Loss: 8.8764
Epoch: 90	Acc: 0.7472	Loss: 8.8449
Epoch: 100	Acc: 0.6358	Loss: 8.7922


              precision    recall  f1-score   support

           0       0.98      0.58      0.73        97
           1       0.71      0.99      0.83       103

    accuracy                           0.79       200
   macro avg       0.85      0.78      0.78       200
weighted avg       0.84      0.79      0.78       200

Training for TP53_8_4
Model 1
[Linear(in_features=6439, out_features=256, bias=True), Linear(in_features=256, out_features=64, bias=True), Linear(in_features=64, out_features=1, bias=True)]
cust_model(
  (model): Sequential(
    (0): Linear(in_features=6439, out_features=256, bias=True)
    (1): Linear(in_features=256, out_features=64, bias=True)
    (2): Linear(in_features=64, out_features=1, bias=True)
  )
  (activation): Sigmoid()
)
Epoch: 10	Acc: 0.8298	Loss: 8.5584
Epoch: 20	Acc: 0.9011	Loss: 7.6066
Epoch: 30	Acc: 0.8999	Loss: 5.7596
Epoch: 40	Acc: 0.9136	Loss: 3.9407
Epoch: 50	Acc: 0.9274	Loss: 3.0359
Epoch: 60	Acc: 0.9424	Loss: 2.4691
Epoch: 70	Acc: 0.9462	Loss: 2.2529
Epoch: 80	Acc: 0.9549	Loss: 2.0027
Epoch: 90	Acc: 0.9599	Loss: 1.8663
Epoch: 100	Acc: 0.9612	Loss: 1.699
Epoch: 110	Acc: 0.9637	Loss: 1.6771
Epoch: 120	Acc: 0.9687	Loss: 1.5839
Epoch: 130	Acc: 0.9687	Loss: 1.4472
Epoch: 140	Acc: 0.9687	Loss: 1.4758
Epoch: 150	Acc: 0.9687	Loss: 1.4203
Epoch: 160	Acc: 0.9712	Loss: 1.4304
Epoch: 170	Acc: 0.9712	Loss: 1.4248
Epoch: 180	Acc: 0.9737	Loss: 1.3756
Epoch: 190	Acc: 0.9687	Loss: 1.4015
Epoch: 200	Acc: 0.9725	Loss: 1.315


              precision    recall  f1-score   support

           0       1.00      0.94      0.97       106
           1       0.94      1.00      0.97        94

    accuracy                           0.97       200
   macro avg       0.97      0.97      0.97       200
weighted avg       0.97      0.97      0.97       200

Model 2
[Linear(in_features=6439, out_features=256, bias=True), Dropout(p=0.25, inplace=False), Linear(in_features=256, out_features=64, bias=True), Dropout(p=0.25, inplace=False), Linear(in_features=64, out_features=1, bias=True)]
cust_model(
  (model): Sequential(
    (0): Linear(in_features=6439, out_features=256, bias=True)
    (1): Dropout(p=0.25, inplace=False)
    (2): Linear(in_features=256, out_features=64, bias=True)
    (3): Dropout(p=0.25, inplace=False)
    (4): Linear(in_features=64, out_features=1, bias=True)
  )
  (activation): Sigmoid()
)
Epoch: 10	Acc: 0.7997	Loss: 8.5825
Epoch: 20	Acc: 0.9186	Loss: 7.6991
Epoch: 30	Acc: 0.9124	Loss: 5.9081
Epoch: 40	Acc: 0.9249	Loss: 4.04
Epoch: 50	Acc: 0.9337	Loss: 3.0671
Epoch: 60	Acc: 0.9462	Loss: 2.5884
Epoch: 70	Acc: 0.9487	Loss: 2.2844
Epoch: 80	Acc: 0.9549	Loss: 2.1816
Epoch: 90	Acc: 0.9612	Loss: 1.8765
Epoch: 100	Acc: 0.9625	Loss: 1.787
Epoch: 110	Acc: 0.9625	Loss: 1.7002
Epoch: 120	Acc: 0.97	Loss: 1.6241
Epoch: 130	Acc: 0.9675	Loss: 1.5458
Epoch: 140	Acc: 0.9675	Loss: 1.543
Epoch: 150	Acc: 0.9687	Loss: 1.4947
Epoch: 160	Acc: 0.9687	Loss: 1.4035
Epoch: 170	Acc: 0.9687	Loss: 1.4021
Epoch: 180	Acc: 0.97	Loss: 1.352
Epoch: 190	Acc: 0.9712	Loss: 1.4023
Epoch: 200	Acc: 0.9737	Loss: 1.3693


              precision    recall  f1-score   support

           0       1.00      0.93      0.96        94
           1       0.94      1.00      0.97       106

    accuracy                           0.96       200
   macro avg       0.97      0.96      0.96       200
weighted avg       0.97      0.96      0.96       200

Model 3
[Linear(in_features=64, out_features=256, bias=True), Linear(in_features=256, out_features=64, bias=True), Linear(in_features=64, out_features=1, bias=True)]
cust_model(
  (conv): Conv1d(1, 64, kernel_size=(8,), stride=(1,))
  (maxpool): MaxPool1d(kernel_size=6432, stride=6432, padding=0, dilation=1, ceil_mode=False)
  (model): Sequential(
    (0): Linear(in_features=64, out_features=256, bias=True)
    (1): Linear(in_features=256, out_features=64, bias=True)
    (2): Linear(in_features=64, out_features=1, bias=True)
  )
  (activation): Sigmoid()
)
Epoch: 10	Acc: 0.4981	Loss: 9.008
Epoch: 20	Acc: 0.5094	Loss: 9.0107
Epoch: 30	Acc: 0.5106	Loss: 9.0039
Epoch: 40	Acc: 0.5156	Loss: 9.0091
Epoch: 50	Acc: 0.5069	Loss: 9.0041
Epoch: 60	Acc: 0.5282	Loss: 9.0025
Epoch: 70	Acc: 0.5294	Loss: 9.0016
Epoch: 80	Acc: 0.5332	Loss: 8.9992
Epoch: 90	Acc: 0.5144	Loss: 8.9964
Epoch: 100	Acc: 0.5232	Loss: 8.999


              precision    recall  f1-score   support

           0       1.00      0.28      0.44       113
           1       0.52      1.00      0.68        87

    accuracy                           0.59       200
   macro avg       0.76      0.64      0.56       200
weighted avg       0.79      0.59      0.55       200

Training for TP53_16_16
Model 1
[Linear(in_features=1610, out_features=256, bias=True), Linear(in_features=256, out_features=64, bias=True), Linear(in_features=64, out_features=1, bias=True)]
cust_model(
  (model): Sequential(
    (0): Linear(in_features=1610, out_features=256, bias=True)
    (1): Linear(in_features=256, out_features=64, bias=True)
    (2): Linear(in_features=64, out_features=1, bias=True)
  )
  (activation): Sigmoid()
)
Epoch: 10	Acc: 0.9024	Loss: 8.7589
Epoch: 20	Acc: 0.9174	Loss: 8.3454
Epoch: 30	Acc: 0.8949	Loss: 7.5083
Epoch: 40	Acc: 0.9111	Loss: 6.0241
Epoch: 50	Acc: 0.9161	Loss: 4.4221
Epoch: 60	Acc: 0.9287	Loss: 3.3978
Epoch: 70	Acc: 0.9374	Loss: 2.8131
Epoch: 80	Acc: 0.9437	Loss: 2.492
Epoch: 90	Acc: 0.9499	Loss: 2.3046
Epoch: 100	Acc: 0.9524	Loss: 2.1589
Epoch: 110	Acc: 0.9549	Loss: 2.0127
Epoch: 120	Acc: 0.9574	Loss: 1.9163
Epoch: 130	Acc: 0.9574	Loss: 1.8506
Epoch: 140	Acc: 0.9612	Loss: 1.8116
Epoch: 150	Acc: 0.9625	Loss: 1.7553
Epoch: 160	Acc: 0.9662	Loss: 1.7717
Epoch: 170	Acc: 0.9637	Loss: 1.5955
Epoch: 180	Acc: 0.9625	Loss: 1.5878
Epoch: 190	Acc: 0.965	Loss: 1.6343
Epoch: 200	Acc: 0.9662	Loss: 1.5712


              precision    recall  f1-score   support

           0       1.00      0.92      0.96        91
           1       0.94      1.00      0.97       109

    accuracy                           0.96       200
   macro avg       0.97      0.96      0.96       200
weighted avg       0.97      0.96      0.96       200

Model 2
[Linear(in_features=1610, out_features=256, bias=True), Dropout(p=0.25, inplace=False), Linear(in_features=256, out_features=64, bias=True), Dropout(p=0.25, inplace=False), Linear(in_features=64, out_features=1, bias=True)]
cust_model(
  (model): Sequential(
    (0): Linear(in_features=1610, out_features=256, bias=True)
    (1): Dropout(p=0.25, inplace=False)
    (2): Linear(in_features=256, out_features=64, bias=True)
    (3): Dropout(p=0.25, inplace=False)
    (4): Linear(in_features=64, out_features=1, bias=True)
  )
  (activation): Sigmoid()
)
Epoch: 10	Acc: 0.7559	Loss: 8.6846
Epoch: 20	Acc: 0.8598	Loss: 8.1146
Epoch: 30	Acc: 0.8949	Loss: 6.966
Epoch: 40	Acc: 0.9036	Loss: 5.3945
Epoch: 50	Acc: 0.9174	Loss: 4.0055
Epoch: 60	Acc: 0.9287	Loss: 3.1465
Epoch: 70	Acc: 0.9399	Loss: 2.7197
Epoch: 80	Acc: 0.9512	Loss: 2.3939
Epoch: 90	Acc: 0.9549	Loss: 2.1796
Epoch: 100	Acc: 0.9537	Loss: 2.0771
Epoch: 110	Acc: 0.9574	Loss: 1.9113
Epoch: 120	Acc: 0.9599	Loss: 1.9863
Epoch: 130	Acc: 0.9599	Loss: 1.9266
Epoch: 140	Acc: 0.9637	Loss: 1.7118
Epoch: 150	Acc: 0.965	Loss: 1.6265
Epoch: 160	Acc: 0.9637	Loss: 1.582
Epoch: 170	Acc: 0.9599	Loss: 1.6604
Epoch: 180	Acc: 0.9625	Loss: 1.6037
Epoch: 190	Acc: 0.965	Loss: 1.5418
Epoch: 200	Acc: 0.9637	Loss: 1.5029


              precision    recall  f1-score   support

           0       1.00      0.91      0.95       101
           1       0.92      1.00      0.96        99

    accuracy                           0.95       200
   macro avg       0.96      0.96      0.95       200
weighted avg       0.96      0.95      0.95       200

Model 3
[Linear(in_features=64, out_features=256, bias=True), Linear(in_features=256, out_features=64, bias=True), Linear(in_features=64, out_features=1, bias=True)]
cust_model(
  (conv): Conv1d(1, 64, kernel_size=(8,), stride=(1,))
  (maxpool): MaxPool1d(kernel_size=1603, stride=1603, padding=0, dilation=1, ceil_mode=False)
  (model): Sequential(
    (0): Linear(in_features=64, out_features=256, bias=True)
    (1): Linear(in_features=256, out_features=64, bias=True)
    (2): Linear(in_features=64, out_features=1, bias=True)
  )
  (activation): Sigmoid()
)
Epoch: 10	Acc: 0.6471	Loss: 8.9512
Epoch: 20	Acc: 0.5069	Loss: 8.888
Epoch: 30	Acc: 0.8423	Loss: 8.7995
Epoch: 40	Acc: 0.8048	Loss: 8.677
Epoch: 50	Acc: 0.8736	Loss: 8.4832
Epoch: 60	Acc: 0.8686	Loss: 8.2002
Epoch: 70	Acc: 0.8523	Loss: 7.769
Epoch: 80	Acc: 0.8573	Loss: 7.1194
Epoch: 90	Acc: 0.8636	Loss: 6.2933
Epoch: 100	Acc: 0.8736	Loss: 5.299


              precision    recall  f1-score   support

           0       0.99      0.79      0.88        91
           1       0.85      0.99      0.92       109

    accuracy                           0.90       200
   macro avg       0.92      0.89      0.90       200
weighted avg       0.91      0.90      0.90       200

Training for TP53_16_8
Model 1
[Linear(in_features=3219, out_features=256, bias=True), Linear(in_features=256, out_features=64, bias=True), Linear(in_features=64, out_features=1, bias=True)]
cust_model(
  (model): Sequential(
    (0): Linear(in_features=3219, out_features=256, bias=True)
    (1): Linear(in_features=256, out_features=64, bias=True)
    (2): Linear(in_features=64, out_features=1, bias=True)
  )
  (activation): Sigmoid()
)
Epoch: 10	Acc: 0.9412	Loss: 8.546
Epoch: 20	Acc: 0.9011	Loss: 7.5718
Epoch: 30	Acc: 0.9074	Loss: 5.5919
Epoch: 40	Acc: 0.9174	Loss: 3.8515
Epoch: 50	Acc: 0.9349	Loss: 2.9838
Epoch: 60	Acc: 0.9474	Loss: 2.5066
Epoch: 70	Acc: 0.9512	Loss: 2.2611
Epoch: 80	Acc: 0.9549	Loss: 2.0465
Epoch: 90	Acc: 0.9562	Loss: 1.9949
Epoch: 100	Acc: 0.9587	Loss: 1.8249
Epoch: 110	Acc: 0.9599	Loss: 1.7472
Epoch: 120	Acc: 0.9612	Loss: 1.799
Epoch: 130	Acc: 0.9625	Loss: 1.6166
Epoch: 140	Acc: 0.9637	Loss: 1.6105
Epoch: 150	Acc: 0.9662	Loss: 1.5776
Epoch: 160	Acc: 0.965	Loss: 1.5125
Epoch: 170	Acc: 0.9662	Loss: 1.5386
Epoch: 180	Acc: 0.9662	Loss: 1.5681
Epoch: 190	Acc: 0.9675	Loss: 1.4899
Epoch: 200	Acc: 0.9662	Loss: 1.5502


              precision    recall  f1-score   support

           0       1.00      0.91      0.95        91
           1       0.93      1.00      0.96       109

    accuracy                           0.96       200
   macro avg       0.97      0.96      0.96       200
weighted avg       0.96      0.96      0.96       200

Model 2
[Linear(in_features=3219, out_features=256, bias=True), Dropout(p=0.25, inplace=False), Linear(in_features=256, out_features=64, bias=True), Dropout(p=0.25, inplace=False), Linear(in_features=64, out_features=1, bias=True)]
cust_model(
  (model): Sequential(
    (0): Linear(in_features=3219, out_features=256, bias=True)
    (1): Dropout(p=0.25, inplace=False)
    (2): Linear(in_features=256, out_features=64, bias=True)
    (3): Dropout(p=0.25, inplace=False)
    (4): Linear(in_features=64, out_features=1, bias=True)
  )
  (activation): Sigmoid()
)
Epoch: 10	Acc: 0.826	Loss: 8.3563
Epoch: 20	Acc: 0.8824	Loss: 7.0357
Epoch: 30	Acc: 0.9036	Loss: 4.8233
Epoch: 40	Acc: 0.9249	Loss: 3.4401
Epoch: 50	Acc: 0.9437	Loss: 2.8122
Epoch: 60	Acc: 0.9474	Loss: 2.4268
Epoch: 70	Acc: 0.9524	Loss: 2.1582
Epoch: 80	Acc: 0.9587	Loss: 2.0762
Epoch: 90	Acc: 0.9549	Loss: 1.9395
Epoch: 100	Acc: 0.9587	Loss: 1.8513
Epoch: 110	Acc: 0.9599	Loss: 1.7658
Epoch: 120	Acc: 0.9625	Loss: 1.7461
Epoch: 130	Acc: 0.9599	Loss: 1.7107
Epoch: 140	Acc: 0.9675	Loss: 1.6051
Epoch: 150	Acc: 0.9625	Loss: 1.756
Epoch: 160	Acc: 0.965	Loss: 1.619
Epoch: 170	Acc: 0.9675	Loss: 1.5927
Epoch: 180	Acc: 0.965	Loss: 1.5816
Epoch: 190	Acc: 0.965	Loss: 1.5505
Epoch: 200	Acc: 0.9675	Loss: 1.4745


              precision    recall  f1-score   support

           0       1.00      0.91      0.96       105
           1       0.91      1.00      0.95        95

    accuracy                           0.95       200
   macro avg       0.96      0.96      0.95       200
weighted avg       0.96      0.95      0.96       200

Model 3
[Linear(in_features=64, out_features=256, bias=True), Linear(in_features=256, out_features=64, bias=True), Linear(in_features=64, out_features=1, bias=True)]
cust_model(
  (conv): Conv1d(1, 64, kernel_size=(8,), stride=(1,))
  (maxpool): MaxPool1d(kernel_size=3212, stride=3212, padding=0, dilation=1, ceil_mode=False)
  (model): Sequential(
    (0): Linear(in_features=64, out_features=256, bias=True)
    (1): Linear(in_features=256, out_features=64, bias=True)
    (2): Linear(in_features=64, out_features=1, bias=True)
  )
  (activation): Sigmoid()
)
Epoch: 10	Acc: 0.4956	Loss: 9.01
Epoch: 20	Acc: 0.5181	Loss: 9.001
Epoch: 30	Acc: 0.5632	Loss: 8.9737
Epoch: 40	Acc: 0.5557	Loss: 8.9533
Epoch: 50	Acc: 0.6671	Loss: 8.9239
Epoch: 60	Acc: 0.6483	Loss: 8.9002
Epoch: 70	Acc: 0.7685	Loss: 8.8535
Epoch: 80	Acc: 0.7747	Loss: 8.804
Epoch: 90	Acc: 0.7472	Loss: 8.7357
Epoch: 100	Acc: 0.8073	Loss: 8.6305


              precision    recall  f1-score   support

           0       0.83      0.87      0.85       103
           1       0.86      0.80      0.83        97

    accuracy                           0.84       200
   macro avg       0.84      0.84      0.84       200
weighted avg       0.84      0.84      0.84       200

Training for TP53_14_14
Model 1
[Linear(in_features=1840, out_features=256, bias=True), Linear(in_features=256, out_features=64, bias=True), Linear(in_features=64, out_features=1, bias=True)]
cust_model(
  (model): Sequential(
    (0): Linear(in_features=1840, out_features=256, bias=True)
    (1): Linear(in_features=256, out_features=64, bias=True)
    (2): Linear(in_features=64, out_features=1, bias=True)
  )
  (activation): Sigmoid()
)
Epoch: 10	Acc: 0.7084	Loss: 8.8283
Epoch: 20	Acc: 0.831	Loss: 8.527
Epoch: 30	Acc: 0.8573	Loss: 7.9802
Epoch: 40	Acc: 0.8961	Loss: 6.8794
Epoch: 50	Acc: 0.8949	Loss: 5.3584
Epoch: 60	Acc: 0.9111	Loss: 4.0973
Epoch: 70	Acc: 0.9262	Loss: 3.3422
Epoch: 80	Acc: 0.9299	Loss: 2.9423
Epoch: 90	Acc: 0.9387	Loss: 2.6906
Epoch: 100	Acc: 0.9412	Loss: 2.4068
Epoch: 110	Acc: 0.9462	Loss: 2.3169
Epoch: 120	Acc: 0.9487	Loss: 2.2553
Epoch: 130	Acc: 0.9512	Loss: 2.1562
Epoch: 140	Acc: 0.9524	Loss: 1.9951
Epoch: 150	Acc: 0.9524	Loss: 1.9286
Epoch: 160	Acc: 0.9537	Loss: 1.9511
Epoch: 170	Acc: 0.9537	Loss: 1.9441
Epoch: 180	Acc: 0.9599	Loss: 1.8386
Epoch: 190	Acc: 0.9574	Loss: 1.8505
Epoch: 200	Acc: 0.9612	Loss: 1.7715


              precision    recall  f1-score   support

           0       1.00      0.94      0.97       105
           1       0.94      1.00      0.97        95

    accuracy                           0.97       200
   macro avg       0.97      0.97      0.97       200
weighted avg       0.97      0.97      0.97       200

Model 2
[Linear(in_features=1840, out_features=256, bias=True), Dropout(p=0.25, inplace=False), Linear(in_features=256, out_features=64, bias=True), Dropout(p=0.25, inplace=False), Linear(in_features=64, out_features=1, bias=True)]
cust_model(
  (model): Sequential(
    (0): Linear(in_features=1840, out_features=256, bias=True)
    (1): Dropout(p=0.25, inplace=False)
    (2): Linear(in_features=256, out_features=64, bias=True)
    (3): Dropout(p=0.25, inplace=False)
    (4): Linear(in_features=64, out_features=1, bias=True)
  )
  (activation): Sigmoid()
)
Epoch: 10	Acc: 0.7735	Loss: 8.7607
Epoch: 20	Acc: 0.8636	Loss: 8.3455
Epoch: 30	Acc: 0.8798	Loss: 7.5828
Epoch: 40	Acc: 0.8811	Loss: 6.1184
Epoch: 50	Acc: 0.9074	Loss: 4.5856
Epoch: 60	Acc: 0.9262	Loss: 3.5655
Epoch: 70	Acc: 0.9349	Loss: 2.9435
Epoch: 80	Acc: 0.9474	Loss: 2.5318
Epoch: 90	Acc: 0.9512	Loss: 2.2483
Epoch: 100	Acc: 0.9524	Loss: 2.0792
Epoch: 110	Acc: 0.9574	Loss: 1.9757
Epoch: 120	Acc: 0.9599	Loss: 1.8732
Epoch: 130	Acc: 0.9625	Loss: 1.7507
Epoch: 140	Acc: 0.9637	Loss: 1.692
Epoch: 150	Acc: 0.9687	Loss: 1.6189
Epoch: 160	Acc: 0.9662	Loss: 1.6136
Epoch: 170	Acc: 0.9662	Loss: 1.5944
Epoch: 180	Acc: 0.97	Loss: 1.5059
Epoch: 190	Acc: 0.9687	Loss: 1.4845
Epoch: 200	Acc: 0.9687	Loss: 1.4449


              precision    recall  f1-score   support

           0       1.00      0.85      0.92       105
           1       0.86      1.00      0.92        95

    accuracy                           0.92       200
   macro avg       0.93      0.92      0.92       200
weighted avg       0.93      0.92      0.92       200

Model 3
[Linear(in_features=64, out_features=256, bias=True), Linear(in_features=256, out_features=64, bias=True), Linear(in_features=64, out_features=1, bias=True)]
cust_model(
  (conv): Conv1d(1, 64, kernel_size=(8,), stride=(1,))
  (maxpool): MaxPool1d(kernel_size=1833, stride=1833, padding=0, dilation=1, ceil_mode=False)
  (model): Sequential(
    (0): Linear(in_features=64, out_features=256, bias=True)
    (1): Linear(in_features=256, out_features=64, bias=True)
    (2): Linear(in_features=64, out_features=1, bias=True)
  )
  (activation): Sigmoid()
)
Epoch: 10	Acc: 0.4881	Loss: 9.0128
Epoch: 20	Acc: 0.5056	Loss: 8.9883
Epoch: 30	Acc: 0.6796	Loss: 8.9643
Epoch: 40	Acc: 0.6183	Loss: 8.9346
Epoch: 50	Acc: 0.5582	Loss: 8.9038
Epoch: 60	Acc: 0.617	Loss: 8.8584
Epoch: 70	Acc: 0.8436	Loss: 8.7993
Epoch: 80	Acc: 0.7196	Loss: 8.7344
Epoch: 90	Acc: 0.811	Loss: 8.6183
Epoch: 100	Acc: 0.8423	Loss: 8.4579


              precision    recall  f1-score   support

           0       0.99      0.81      0.89       100
           1       0.84      0.99      0.91       100

    accuracy                           0.90       200
   macro avg       0.91      0.90      0.90       200
weighted avg       0.91      0.90      0.90       200

Training for TP53_14_7
Model 1
[Linear(in_features=3679, out_features=256, bias=True), Linear(in_features=256, out_features=64, bias=True), Linear(in_features=64, out_features=1, bias=True)]
cust_model(
  (model): Sequential(
    (0): Linear(in_features=3679, out_features=256, bias=True)
    (1): Linear(in_features=256, out_features=64, bias=True)
    (2): Linear(in_features=64, out_features=1, bias=True)
  )
  (activation): Sigmoid()
)
Epoch: 10	Acc: 0.806	Loss: 8.545
Epoch: 20	Acc: 0.8886	Loss: 7.5696
Epoch: 30	Acc: 0.8961	Loss: 5.6752
Epoch: 40	Acc: 0.9274	Loss: 3.9128
Epoch: 50	Acc: 0.9349	Loss: 3.0131
Epoch: 60	Acc: 0.9437	Loss: 2.4842
Epoch: 70	Acc: 0.9487	Loss: 2.2591
Epoch: 80	Acc: 0.9549	Loss: 1.9818
Epoch: 90	Acc: 0.9562	Loss: 1.913
Epoch: 100	Acc: 0.9612	Loss: 1.732
Epoch: 110	Acc: 0.9637	Loss: 1.7374
Epoch: 120	Acc: 0.9625	Loss: 1.6154
Epoch: 130	Acc: 0.9662	Loss: 1.652
Epoch: 140	Acc: 0.9662	Loss: 1.4803
Epoch: 150	Acc: 0.97	Loss: 1.5173
Epoch: 160	Acc: 0.9675	Loss: 1.5676
Epoch: 170	Acc: 0.97	Loss: 1.6068
Epoch: 180	Acc: 0.9675	Loss: 1.5189
Epoch: 190	Acc: 0.97	Loss: 1.4266
Epoch: 200	Acc: 0.9712	Loss: 1.3504


              precision    recall  f1-score   support

           0       1.00      0.92      0.96       101
           1       0.93      1.00      0.96        99

    accuracy                           0.96       200
   macro avg       0.96      0.96      0.96       200
weighted avg       0.96      0.96      0.96       200

Model 2
[Linear(in_features=3679, out_features=256, bias=True), Dropout(p=0.25, inplace=False), Linear(in_features=256, out_features=64, bias=True), Dropout(p=0.25, inplace=False), Linear(in_features=64, out_features=1, bias=True)]
cust_model(
  (model): Sequential(
    (0): Linear(in_features=3679, out_features=256, bias=True)
    (1): Dropout(p=0.25, inplace=False)
    (2): Linear(in_features=256, out_features=64, bias=True)
    (3): Dropout(p=0.25, inplace=False)
    (4): Linear(in_features=64, out_features=1, bias=True)
  )
  (activation): Sigmoid()
)
Epoch: 10	Acc: 0.8648	Loss: 8.4969
Epoch: 20	Acc: 0.8736	Loss: 7.469
Epoch: 30	Acc: 0.8911	Loss: 5.5956
Epoch: 40	Acc: 0.9262	Loss: 3.8578
Epoch: 50	Acc: 0.9337	Loss: 3.0607
Epoch: 60	Acc: 0.9462	Loss: 2.5238
Epoch: 70	Acc: 0.9524	Loss: 2.2128
Epoch: 80	Acc: 0.9599	Loss: 2.0657
Epoch: 90	Acc: 0.9562	Loss: 1.9233
Epoch: 100	Acc: 0.9637	Loss: 1.7654
Epoch: 110	Acc: 0.9599	Loss: 1.678
Epoch: 120	Acc: 0.965	Loss: 1.6215
Epoch: 130	Acc: 0.97	Loss: 1.5175
Epoch: 140	Acc: 0.9687	Loss: 1.5192
Epoch: 150	Acc: 0.97	Loss: 1.5651
Epoch: 160	Acc: 0.9712	Loss: 1.4653
Epoch: 170	Acc: 0.9712	Loss: 1.457
Epoch: 180	Acc: 0.97	Loss: 1.4511
Epoch: 190	Acc: 0.9725	Loss: 1.4447
Epoch: 200	Acc: 0.97	Loss: 1.4247


              precision    recall  f1-score   support

           0       1.00      0.92      0.96        97
           1       0.93      1.00      0.96       103

    accuracy                           0.96       200
   macro avg       0.96      0.96      0.96       200
weighted avg       0.96      0.96      0.96       200

Model 3
[Linear(in_features=64, out_features=256, bias=True), Linear(in_features=256, out_features=64, bias=True), Linear(in_features=64, out_features=1, bias=True)]
cust_model(
  (conv): Conv1d(1, 64, kernel_size=(8,), stride=(1,))
  (maxpool): MaxPool1d(kernel_size=3672, stride=3672, padding=0, dilation=1, ceil_mode=False)
  (model): Sequential(
    (0): Linear(in_features=64, out_features=256, bias=True)
    (1): Linear(in_features=256, out_features=64, bias=True)
    (2): Linear(in_features=64, out_features=1, bias=True)
  )
  (activation): Sigmoid()
)
Epoch: 10	Acc: 0.5044	Loss: 9.0071
Epoch: 20	Acc: 0.5469	Loss: 8.9889
Epoch: 30	Acc: 0.5782	Loss: 8.9717
Epoch: 40	Acc: 0.5857	Loss: 8.952
Epoch: 50	Acc: 0.6083	Loss: 8.9351
Epoch: 60	Acc: 0.7134	Loss: 8.9003
Epoch: 70	Acc: 0.7572	Loss: 8.864
Epoch: 80	Acc: 0.6984	Loss: 8.8114
Epoch: 90	Acc: 0.816	Loss: 8.7534
Epoch: 100	Acc: 0.8436	Loss: 8.6617


              precision    recall  f1-score   support

           0       1.00      0.63      0.78       101
           1       0.73      1.00      0.84        99

    accuracy                           0.81       200
   macro avg       0.86      0.82      0.81       200
weighted avg       0.87      0.81      0.81       200

Training for TP53_10_10
Model 1
[Linear(in_features=2576, out_features=256, bias=True), Linear(in_features=256, out_features=64, bias=True), Linear(in_features=64, out_features=1, bias=True)]
cust_model(
  (model): Sequential(
    (0): Linear(in_features=2576, out_features=256, bias=True)
    (1): Linear(in_features=256, out_features=64, bias=True)
    (2): Linear(in_features=64, out_features=1, bias=True)
  )
  (activation): Sigmoid()
)
Epoch: 10	Acc: 0.831	Loss: 8.8016
Epoch: 20	Acc: 0.9287	Loss: 8.4557
Epoch: 30	Acc: 0.9149	Loss: 7.8055
Epoch: 40	Acc: 0.8974	Loss: 6.5469
Epoch: 50	Acc: 0.9124	Loss: 4.9319
Epoch: 60	Acc: 0.9136	Loss: 3.7552
Epoch: 70	Acc: 0.9324	Loss: 3.1311
Epoch: 80	Acc: 0.9437	Loss: 2.6352
Epoch: 90	Acc: 0.9524	Loss: 2.346
Epoch: 100	Acc: 0.9549	Loss: 2.1748
Epoch: 110	Acc: 0.9562	Loss: 2.0713
Epoch: 120	Acc: 0.9587	Loss: 1.9076
Epoch: 130	Acc: 0.9612	Loss: 1.8918
Epoch: 140	Acc: 0.9612	Loss: 1.771
Epoch: 150	Acc: 0.9637	Loss: 1.6798
Epoch: 160	Acc: 0.965	Loss: 1.7476
Epoch: 170	Acc: 0.9637	Loss: 1.6894
Epoch: 180	Acc: 0.9675	Loss: 1.5728
Epoch: 190	Acc: 0.965	Loss: 1.52
Epoch: 200	Acc: 0.9662	Loss: 1.5257


              precision    recall  f1-score   support

           0       1.00      0.93      0.96        94
           1       0.94      1.00      0.97       106

    accuracy                           0.96       200
   macro avg       0.97      0.96      0.96       200
weighted avg       0.97      0.96      0.96       200

Model 2
[Linear(in_features=2576, out_features=256, bias=True), Dropout(p=0.25, inplace=False), Linear(in_features=256, out_features=64, bias=True), Dropout(p=0.25, inplace=False), Linear(in_features=64, out_features=1, bias=True)]
cust_model(
  (model): Sequential(
    (0): Linear(in_features=2576, out_features=256, bias=True)
    (1): Dropout(p=0.25, inplace=False)
    (2): Linear(in_features=256, out_features=64, bias=True)
    (3): Dropout(p=0.25, inplace=False)
    (4): Linear(in_features=64, out_features=1, bias=True)
  )
  (activation): Sigmoid()
)
Epoch: 10	Acc: 0.7672	Loss: 8.8092
Epoch: 20	Acc: 0.8273	Loss: 8.4749
Epoch: 30	Acc: 0.8786	Loss: 7.8658
Epoch: 40	Acc: 0.8786	Loss: 6.677
Epoch: 50	Acc: 0.9049	Loss: 5.0744
Epoch: 60	Acc: 0.9237	Loss: 3.795
Epoch: 70	Acc: 0.9362	Loss: 3.1936
Epoch: 80	Acc: 0.9474	Loss: 2.7478
Epoch: 90	Acc: 0.9437	Loss: 2.4654
Epoch: 100	Acc: 0.9512	Loss: 2.2779
Epoch: 110	Acc: 0.9524	Loss: 2.2065
Epoch: 120	Acc: 0.9599	Loss: 2.0376
Epoch: 130	Acc: 0.9612	Loss: 1.9253
Epoch: 140	Acc: 0.9625	Loss: 1.7858
Epoch: 150	Acc: 0.9612	Loss: 1.7874
Epoch: 160	Acc: 0.9637	Loss: 1.7957
Epoch: 170	Acc: 0.9625	Loss: 1.7673
Epoch: 180	Acc: 0.965	Loss: 1.7043
Epoch: 190	Acc: 0.9637	Loss: 1.6545
Epoch: 200	Acc: 0.9637	Loss: 1.752


              precision    recall  f1-score   support

           0       1.00      0.95      0.98       105
           1       0.95      1.00      0.97        95

    accuracy                           0.97       200
   macro avg       0.97      0.98      0.97       200
weighted avg       0.98      0.97      0.98       200

Model 3
[Linear(in_features=64, out_features=256, bias=True), Linear(in_features=256, out_features=64, bias=True), Linear(in_features=64, out_features=1, bias=True)]
cust_model(
  (conv): Conv1d(1, 64, kernel_size=(8,), stride=(1,))
  (maxpool): MaxPool1d(kernel_size=2569, stride=2569, padding=0, dilation=1, ceil_mode=False)
  (model): Sequential(
    (0): Linear(in_features=64, out_features=256, bias=True)
    (1): Linear(in_features=256, out_features=64, bias=True)
    (2): Linear(in_features=64, out_features=1, bias=True)
  )
  (activation): Sigmoid()
)
Epoch: 10	Acc: 0.5144	Loss: 9.0154
Epoch: 20	Acc: 0.5144	Loss: 8.9884
Epoch: 30	Acc: 0.5144	Loss: 8.965
Epoch: 40	Acc: 0.5169	Loss: 8.9364
Epoch: 50	Acc: 0.5144	Loss: 8.9101
Epoch: 60	Acc: 0.5144	Loss: 8.8798
Epoch: 70	Acc: 0.5257	Loss: 8.8381
Epoch: 80	Acc: 0.5257	Loss: 8.7854
Epoch: 90	Acc: 0.7547	Loss: 8.7198
Epoch: 100	Acc: 0.7622	Loss: 8.6196


              precision    recall  f1-score   support

           0       0.96      0.55      0.70        94
           1       0.71      0.98      0.83       106

    accuracy                           0.78       200
   macro avg       0.84      0.77      0.76       200
weighted avg       0.83      0.78      0.77       200

Training for TP53_10_5
Model 1
[Linear(in_features=5151, out_features=256, bias=True), Linear(in_features=256, out_features=64, bias=True), Linear(in_features=64, out_features=1, bias=True)]
cust_model(
  (model): Sequential(
    (0): Linear(in_features=5151, out_features=256, bias=True)
    (1): Linear(in_features=256, out_features=64, bias=True)
    (2): Linear(in_features=64, out_features=1, bias=True)
  )
  (activation): Sigmoid()
)
Epoch: 10	Acc: 0.9036	Loss: 8.6429
Epoch: 20	Acc: 0.9199	Loss: 7.8501
Epoch: 30	Acc: 0.9086	Loss: 6.0816
Epoch: 40	Acc: 0.9124	Loss: 4.1671
Epoch: 50	Acc: 0.9324	Loss: 3.0573
Epoch: 60	Acc: 0.9462	Loss: 2.55
Epoch: 70	Acc: 0.9512	Loss: 2.2173
Epoch: 80	Acc: 0.9562	Loss: 1.9346
Epoch: 90	Acc: 0.9599	Loss: 1.8104
Epoch: 100	Acc: 0.9625	Loss: 1.7639
Epoch: 110	Acc: 0.9637	Loss: 1.7102
Epoch: 120	Acc: 0.9637	Loss: 1.6304
Epoch: 130	Acc: 0.9637	Loss: 1.6264
Epoch: 140	Acc: 0.9662	Loss: 1.4666
Epoch: 150	Acc: 0.965	Loss: 1.5212
Epoch: 160	Acc: 0.965	Loss: 1.5049
Epoch: 170	Acc: 0.9687	Loss: 1.5024
Epoch: 180	Acc: 0.9687	Loss: 1.4261
Epoch: 190	Acc: 0.9725	Loss: 1.3435
Epoch: 200	Acc: 0.9675	Loss: 1.5009


              precision    recall  f1-score   support

           0       1.00      0.93      0.96       100
           1       0.93      1.00      0.97       100

    accuracy                           0.96       200
   macro avg       0.97      0.97      0.96       200
weighted avg       0.97      0.96      0.96       200

Model 2
[Linear(in_features=5151, out_features=256, bias=True), Dropout(p=0.25, inplace=False), Linear(in_features=256, out_features=64, bias=True), Dropout(p=0.25, inplace=False), Linear(in_features=64, out_features=1, bias=True)]
cust_model(
  (model): Sequential(
    (0): Linear(in_features=5151, out_features=256, bias=True)
    (1): Dropout(p=0.25, inplace=False)
    (2): Linear(in_features=256, out_features=64, bias=True)
    (3): Dropout(p=0.25, inplace=False)
    (4): Linear(in_features=64, out_features=1, bias=True)
  )
  (activation): Sigmoid()
)
Epoch: 10	Acc: 0.8273	Loss: 8.5938
Epoch: 20	Acc: 0.8761	Loss: 7.7874
Epoch: 30	Acc: 0.8936	Loss: 6.0548
Epoch: 40	Acc: 0.9262	Loss: 4.129
Epoch: 50	Acc: 0.9362	Loss: 3.2
Epoch: 60	Acc: 0.9437	Loss: 2.6286
Epoch: 70	Acc: 0.9474	Loss: 2.3414
Epoch: 80	Acc: 0.9537	Loss: 2.1769
Epoch: 90	Acc: 0.9574	Loss: 2.0357
Epoch: 100	Acc: 0.9574	Loss: 2.0055
Epoch: 110	Acc: 0.9599	Loss: 1.8177
Epoch: 120	Acc: 0.9612	Loss: 1.7752
Epoch: 130	Acc: 0.9625	Loss: 1.7144
Epoch: 140	Acc: 0.9625	Loss: 1.7072
Epoch: 150	Acc: 0.9637	Loss: 1.6596
Epoch: 160	Acc: 0.9637	Loss: 1.6598
Epoch: 170	Acc: 0.965	Loss: 1.5689
Epoch: 180	Acc: 0.965	Loss: 1.5734
Epoch: 190	Acc: 0.965	Loss: 1.6193
Epoch: 200	Acc: 0.965	Loss: 1.8583


              precision    recall  f1-score   support

           0       0.58      1.00      0.73       103
           1       1.00      0.22      0.36        97

    accuracy                           0.62       200
   macro avg       0.79      0.61      0.54       200
weighted avg       0.78      0.62      0.55       200

Model 3
[Linear(in_features=64, out_features=256, bias=True), Linear(in_features=256, out_features=64, bias=True), Linear(in_features=64, out_features=1, bias=True)]
cust_model(
  (conv): Conv1d(1, 64, kernel_size=(8,), stride=(1,))
  (maxpool): MaxPool1d(kernel_size=5144, stride=5144, padding=0, dilation=1, ceil_mode=False)
  (model): Sequential(
    (0): Linear(in_features=64, out_features=256, bias=True)
    (1): Linear(in_features=256, out_features=64, bias=True)
    (2): Linear(in_features=64, out_features=1, bias=True)
  )
  (activation): Sigmoid()
)
Epoch: 10	Acc: 0.4819	Loss: 9.0206
Epoch: 20	Acc: 0.4994	Loss: 9.0127
Epoch: 30	Acc: 0.5081	Loss: 9.0153
Epoch: 40	Acc: 0.5207	Loss: 9.0054
Epoch: 50	Acc: 0.5156	Loss: 9.0073
Epoch: 60	Acc: 0.5081	Loss: 9.004
Epoch: 70	Acc: 0.4956	Loss: 9.0058
Epoch: 80	Acc: 0.5169	Loss: 8.9952
Epoch: 90	Acc: 0.5169	Loss: 9.0008
Epoch: 100	Acc: 0.5294	Loss: 9.0005


              precision    recall  f1-score   support

           0       0.52      1.00      0.68       104
           1       0.00      0.00      0.00        96

    accuracy                           0.52       200
   macro avg       0.26      0.50      0.34       200
weighted avg       0.27      0.52      0.36       200

Training for TP53_4_4
Model 1
[Linear(in_features=6440, out_features=256, bias=True), Linear(in_features=256, out_features=64, bias=True), Linear(in_features=64, out_features=1, bias=True)]
cust_model(
  (model): Sequential(
    (0): Linear(in_features=6440, out_features=256, bias=True)
    (1): Linear(in_features=256, out_features=64, bias=True)
    (2): Linear(in_features=64, out_features=1, bias=True)
  )
  (activation): Sigmoid()
)
Epoch: 10	Acc: 0.5569	Loss: 8.7743
Epoch: 20	Acc: 0.7685	Loss: 8.4059
Epoch: 30	Acc: 0.8323	Loss: 7.7011
Epoch: 40	Acc: 0.8761	Loss: 6.3766
Epoch: 50	Acc: 0.9036	Loss: 4.797
Epoch: 60	Acc: 0.9161	Loss: 3.6669
Epoch: 70	Acc: 0.9262	Loss: 3.106
Epoch: 80	Acc: 0.9387	Loss: 2.6884
Epoch: 90	Acc: 0.9437	Loss: 2.4985
Epoch: 100	Acc: 0.9474	Loss: 2.2908
Epoch: 110	Acc: 0.9499	Loss: 2.1133
Epoch: 120	Acc: 0.9462	Loss: 2.0716
Epoch: 130	Acc: 0.9524	Loss: 1.9212
Epoch: 140	Acc: 0.9524	Loss: 1.9107
Epoch: 150	Acc: 0.9562	Loss: 1.8737
Epoch: 160	Acc: 0.9574	Loss: 1.8172
Epoch: 170	Acc: 0.9587	Loss: 1.7291
Epoch: 180	Acc: 0.9599	Loss: 1.7678
Epoch: 190	Acc: 0.9599	Loss: 1.6477
Epoch: 200	Acc: 0.9599	Loss: 1.6815


              precision    recall  f1-score   support

           0       1.00      0.95      0.98       104
           1       0.95      1.00      0.97        96

    accuracy                           0.97       200
   macro avg       0.98      0.98      0.97       200
weighted avg       0.98      0.97      0.98       200

Model 2
[Linear(in_features=6440, out_features=256, bias=True), Dropout(p=0.25, inplace=False), Linear(in_features=256, out_features=64, bias=True), Dropout(p=0.25, inplace=False), Linear(in_features=64, out_features=1, bias=True)]
cust_model(
  (model): Sequential(
    (0): Linear(in_features=6440, out_features=256, bias=True)
    (1): Dropout(p=0.25, inplace=False)
    (2): Linear(in_features=256, out_features=64, bias=True)
    (3): Dropout(p=0.25, inplace=False)
    (4): Linear(in_features=64, out_features=1, bias=True)
  )
  (activation): Sigmoid()
)
Epoch: 10	Acc: 0.7309	Loss: 8.8317
Epoch: 20	Acc: 0.8573	Loss: 8.4872
Epoch: 30	Acc: 0.8798	Loss: 7.8438
Epoch: 40	Acc: 0.8861	Loss: 6.5577
Epoch: 50	Acc: 0.9074	Loss: 4.9194
Epoch: 60	Acc: 0.9274	Loss: 3.9065
Epoch: 70	Acc: 0.9312	Loss: 3.1475
Epoch: 80	Acc: 0.9374	Loss: 2.7566
Epoch: 90	Acc: 0.9399	Loss: 2.5158
Epoch: 100	Acc: 0.9449	Loss: 2.3491
Epoch: 110	Acc: 0.9474	Loss: 2.2453
Epoch: 120	Acc: 0.9487	Loss: 1.9786
Epoch: 130	Acc: 0.9537	Loss: 2.0218
Epoch: 140	Acc: 0.9537	Loss: 1.9558
Epoch: 150	Acc: 0.9537	Loss: 1.953
Epoch: 160	Acc: 0.9625	Loss: 1.7765
Epoch: 170	Acc: 0.9599	Loss: 1.8447
Epoch: 180	Acc: 0.9587	Loss: 1.7327
Epoch: 190	Acc: 0.9612	Loss: 1.6429
Epoch: 200	Acc: 0.9625	Loss: 1.742


              precision    recall  f1-score   support

           0       1.00      0.95      0.97        91
           1       0.96      1.00      0.98       109

    accuracy                           0.97       200
   macro avg       0.98      0.97      0.97       200
weighted avg       0.98      0.97      0.97       200

Model 3
[Linear(in_features=64, out_features=256, bias=True), Linear(in_features=256, out_features=64, bias=True), Linear(in_features=64, out_features=1, bias=True)]
cust_model(
  (conv): Conv1d(1, 64, kernel_size=(8,), stride=(1,))
  (maxpool): MaxPool1d(kernel_size=6433, stride=6433, padding=0, dilation=1, ceil_mode=False)
  (model): Sequential(
    (0): Linear(in_features=64, out_features=256, bias=True)
    (1): Linear(in_features=256, out_features=64, bias=True)
    (2): Linear(in_features=64, out_features=1, bias=True)
  )
  (activation): Sigmoid()
)
Epoch: 10	Acc: 0.5019	Loss: 9.0022
Epoch: 20	Acc: 0.5557	Loss: 8.9904
Epoch: 30	Acc: 0.632	Loss: 8.9868
Epoch: 40	Acc: 0.6195	Loss: 8.9745
Epoch: 50	Acc: 0.6383	Loss: 8.9716
Epoch: 60	Acc: 0.6345	Loss: 8.9663
Epoch: 70	Acc: 0.5657	Loss: 8.9464
Epoch: 80	Acc: 0.572	Loss: 8.938
Epoch: 90	Acc: 0.6408	Loss: 8.9187
Epoch: 100	Acc: 0.6433	Loss: 8.9005


              precision    recall  f1-score   support

           0       1.00      0.31      0.47        91
           1       0.63      1.00      0.78       109

    accuracy                           0.69       200
   macro avg       0.82      0.65      0.62       200
weighted avg       0.80      0.69      0.64       200

Training for TP53_4_2
Model 1
[Linear(in_features=12879, out_features=256, bias=True), Linear(in_features=256, out_features=64, bias=True), Linear(in_features=64, out_features=1, bias=True)]
cust_model(
  (model): Sequential(
    (0): Linear(in_features=12879, out_features=256, bias=True)
    (1): Linear(in_features=256, out_features=64, bias=True)
    (2): Linear(in_features=64, out_features=1, bias=True)
  )
  (activation): Sigmoid()
)
Epoch: 10	Acc: 0.8886	Loss: 8.4054
Epoch: 20	Acc: 0.9024	Loss: 7.1551
Epoch: 30	Acc: 0.9061	Loss: 5.0296
Epoch: 40	Acc: 0.9274	Loss: 3.5288
Epoch: 50	Acc: 0.9399	Loss: 2.9774
Epoch: 60	Acc: 0.9412	Loss: 2.4363
Epoch: 70	Acc: 0.9499	Loss: 2.2579
Epoch: 80	Acc: 0.9562	Loss: 2.0636
Epoch: 90	Acc: 0.9574	Loss: 1.9609
Epoch: 100	Acc: 0.9549	Loss: 1.8629
Epoch: 110	Acc: 0.9599	Loss: 1.7902
Epoch: 120	Acc: 0.9625	Loss: 1.8108
Epoch: 130	Acc: 0.965	Loss: 1.7723
Epoch: 140	Acc: 0.965	Loss: 1.6335
Epoch: 150	Acc: 0.9625	Loss: 1.7196
Epoch: 160	Acc: 0.9612	Loss: 1.766
Epoch: 170	Acc: 0.9637	Loss: 1.8103
Epoch: 180	Acc: 0.9662	Loss: 1.5095
Epoch: 190	Acc: 0.9312	Loss: 2.5173
Epoch: 200	Acc: 0.9687	Loss: 1.4891


              precision    recall  f1-score   support

           0       1.00      0.91      0.95        88
           1       0.93      1.00      0.97       112

    accuracy                           0.96       200
   macro avg       0.97      0.95      0.96       200
weighted avg       0.96      0.96      0.96       200

Model 2
[Linear(in_features=12879, out_features=256, bias=True), Dropout(p=0.25, inplace=False), Linear(in_features=256, out_features=64, bias=True), Dropout(p=0.25, inplace=False), Linear(in_features=64, out_features=1, bias=True)]
cust_model(
  (model): Sequential(
    (0): Linear(in_features=12879, out_features=256, bias=True)
    (1): Dropout(p=0.25, inplace=False)
    (2): Linear(in_features=256, out_features=64, bias=True)
    (3): Dropout(p=0.25, inplace=False)
    (4): Linear(in_features=64, out_features=1, bias=True)
  )
  (activation): Sigmoid()
)
Epoch: 10	Acc: 0.8736	Loss: 8.5077
Epoch: 20	Acc: 0.8949	Loss: 7.3868
Epoch: 30	Acc: 0.9099	Loss: 5.3505
Epoch: 40	Acc: 0.9237	Loss: 3.7793
Epoch: 50	Acc: 0.9337	Loss: 3.1057
Epoch: 60	Acc: 0.9399	Loss: 2.5547
Epoch: 70	Acc: 0.9449	Loss: 2.3827
Epoch: 80	Acc: 0.9487	Loss: 2.1844
Epoch: 90	Acc: 0.9474	Loss: 2.0746
Epoch: 100	Acc: 0.9524	Loss: 1.9816
Epoch: 110	Acc: 0.9537	Loss: 1.8978
Epoch: 120	Acc: 0.9549	Loss: 1.9403
Epoch: 130	Acc: 0.9562	Loss: 1.8562
Epoch: 140	Acc: 0.9587	Loss: 1.787
Epoch: 150	Acc: 0.9625	Loss: 1.9298
Epoch: 160	Acc: 0.9599	Loss: 1.748
Epoch: 170	Acc: 0.9625	Loss: 1.5857
Epoch: 180	Acc: 0.9612	Loss: 1.6285
Epoch: 190	Acc: 0.9625	Loss: 1.6477
Epoch: 200	Acc: 0.9662	Loss: 1.4614


              precision    recall  f1-score   support

           0       1.00      0.94      0.97        90
           1       0.96      1.00      0.98       110

    accuracy                           0.97       200
   macro avg       0.98      0.97      0.97       200
weighted avg       0.98      0.97      0.97       200

Model 3
[Linear(in_features=64, out_features=256, bias=True), Linear(in_features=256, out_features=64, bias=True), Linear(in_features=64, out_features=1, bias=True)]
cust_model(
  (conv): Conv1d(1, 64, kernel_size=(8,), stride=(1,))
  (maxpool): MaxPool1d(kernel_size=12872, stride=12872, padding=0, dilation=1, ceil_mode=False)
  (model): Sequential(
    (0): Linear(in_features=64, out_features=256, bias=True)
    (1): Linear(in_features=256, out_features=64, bias=True)
    (2): Linear(in_features=64, out_features=1, bias=True)
  )
  (activation): Sigmoid()
)
Epoch: 10	Acc: 0.5069	Loss: 9.0172
Epoch: 20	Acc: 0.4981	Loss: 9.0155
Epoch: 30	Acc: 0.5069	Loss: 9.0107
Epoch: 40	Acc: 0.5069	Loss: 9.0073
Epoch: 50	Acc: 0.5069	Loss: 9.0162
Epoch: 60	Acc: 0.5106	Loss: 9.0081
Epoch: 70	Acc: 0.5232	Loss: 9.002
Epoch: 80	Acc: 0.5081	Loss: 9.0077
Epoch: 90	Acc: 0.5144	Loss: 8.9982
Epoch: 100	Acc: 0.5031	Loss: 9.0003


              precision    recall  f1-score   support

           0       1.00      0.17      0.29        89
           1       0.60      1.00      0.75       111

    accuracy                           0.63       200
   macro avg       0.80      0.58      0.52       200
weighted avg       0.78      0.63      0.54       200

Training for TP53_2_2
Model 1
[Linear(in_features=12880, out_features=256, bias=True), Linear(in_features=256, out_features=64, bias=True), Linear(in_features=64, out_features=1, bias=True)]
cust_model(
  (model): Sequential(
    (0): Linear(in_features=12880, out_features=256, bias=True)
    (1): Linear(in_features=256, out_features=64, bias=True)
    (2): Linear(in_features=64, out_features=1, bias=True)
  )
  (activation): Sigmoid()
)
Epoch: 10	Acc: 0.796	Loss: 8.7829
Epoch: 20	Acc: 0.8686	Loss: 8.4026
Epoch: 30	Acc: 0.8798	Loss: 7.6326
Epoch: 40	Acc: 0.9074	Loss: 6.1986
Epoch: 50	Acc: 0.9199	Loss: 4.5433
Epoch: 60	Acc: 0.9249	Loss: 3.4042
Epoch: 70	Acc: 0.9374	Loss: 2.8408
Epoch: 80	Acc: 0.9462	Loss: 2.5082
Epoch: 90	Acc: 0.9512	Loss: 2.2022
Epoch: 100	Acc: 0.9512	Loss: 2.0488
Epoch: 110	Acc: 0.9574	Loss: 1.906
Epoch: 120	Acc: 0.9612	Loss: 1.8544
Epoch: 130	Acc: 0.9625	Loss: 1.8898
Epoch: 140	Acc: 0.9612	Loss: 1.763
Epoch: 150	Acc: 0.965	Loss: 1.6168
Epoch: 160	Acc: 0.965	Loss: 1.5828
Epoch: 170	Acc: 0.9712	Loss: 1.5514
Epoch: 180	Acc: 0.9687	Loss: 1.5814
Epoch: 190	Acc: 0.9675	Loss: 1.5641
Epoch: 200	Acc: 0.9687	Loss: 1.4516


              precision    recall  f1-score   support

           0       1.00      0.91      0.95        99
           1       0.92      1.00      0.96       101

    accuracy                           0.95       200
   macro avg       0.96      0.95      0.95       200
weighted avg       0.96      0.95      0.95       200

Model 2
[Linear(in_features=12880, out_features=256, bias=True), Dropout(p=0.25, inplace=False), Linear(in_features=256, out_features=64, bias=True), Dropout(p=0.25, inplace=False), Linear(in_features=64, out_features=1, bias=True)]
cust_model(
  (model): Sequential(
    (0): Linear(in_features=12880, out_features=256, bias=True)
    (1): Dropout(p=0.25, inplace=False)
    (2): Linear(in_features=256, out_features=64, bias=True)
    (3): Dropout(p=0.25, inplace=False)
    (4): Linear(in_features=64, out_features=1, bias=True)
  )
  (activation): Sigmoid()
)
Epoch: 10	Acc: 0.7447	Loss: 8.7484
Epoch: 20	Acc: 0.8824	Loss: 8.3203
Epoch: 30	Acc: 0.8661	Loss: 7.4621
Epoch: 40	Acc: 0.9136	Loss: 5.9684
Epoch: 50	Acc: 0.9099	Loss: 4.4107
Epoch: 60	Acc: 0.9237	Loss: 3.3956
Epoch: 70	Acc: 0.9374	Loss: 2.8926
Epoch: 80	Acc: 0.9437	Loss: 2.5957
Epoch: 90	Acc: 0.9487	Loss: 2.3789
Epoch: 100	Acc: 0.9537	Loss: 2.1245
Epoch: 110	Acc: 0.9612	Loss: 2.0882
Epoch: 120	Acc: 0.9587	Loss: 1.9859
Epoch: 130	Acc: 0.9599	Loss: 1.9571
Epoch: 140	Acc: 0.9612	Loss: 1.8996
Epoch: 150	Acc: 0.9637	Loss: 1.822
Epoch: 160	Acc: 0.9625	Loss: 1.769
Epoch: 170	Acc: 0.9637	Loss: 1.6612
Epoch: 180	Acc: 0.9662	Loss: 1.7377
Epoch: 190	Acc: 0.9637	Loss: 1.6386
Epoch: 200	Acc: 0.965	Loss: 1.681


              precision    recall  f1-score   support

           0       1.00      0.94      0.97       101
           1       0.94      1.00      0.97        99

    accuracy                           0.97       200
   macro avg       0.97      0.97      0.97       200
weighted avg       0.97      0.97      0.97       200

Model 3
[Linear(in_features=64, out_features=256, bias=True), Linear(in_features=256, out_features=64, bias=True), Linear(in_features=64, out_features=1, bias=True)]
cust_model(
  (conv): Conv1d(1, 64, kernel_size=(8,), stride=(1,))
  (maxpool): MaxPool1d(kernel_size=12873, stride=12873, padding=0, dilation=1, ceil_mode=False)
  (model): Sequential(
    (0): Linear(in_features=64, out_features=256, bias=True)
    (1): Linear(in_features=256, out_features=64, bias=True)
    (2): Linear(in_features=64, out_features=1, bias=True)
  )
  (activation): Sigmoid()
)
Epoch: 10	Acc: 0.5282	Loss: 9.0067
Epoch: 20	Acc: 0.5294	Loss: 9.0083
Epoch: 30	Acc: 0.5056	Loss: 9.002
Epoch: 40	Acc: 0.5106	Loss: 9.0007
Epoch: 50	Acc: 0.5232	Loss: 8.9917
Epoch: 60	Acc: 0.5457	Loss: 8.9913
Epoch: 70	Acc: 0.5194	Loss: 8.9838
Epoch: 80	Acc: 0.5582	Loss: 8.9784
Epoch: 90	Acc: 0.5407	Loss: 8.9738
Epoch: 100	Acc: 0.6033	Loss: 8.9663


              precision    recall  f1-score   support

           0       0.50      1.00      0.67        94
           1       1.00      0.12      0.22       106

    accuracy                           0.54       200
   macro avg       0.75      0.56      0.44       200
weighted avg       0.77      0.54      0.43       200

